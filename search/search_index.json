{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to qm40_dataset_for_ml","text":"<p>QM40 is a QMx type of dataset which includes 150K molecules optimized from B3LYP/6-31G(2df,p) level of theory in the Gaussian16 with QM parameters, optimized coordinates, Mulliken charges and Local vibrational mode parameters as a quantitative measurer of the bond strengths.</p> <ul> <li>Free software: MIT License</li> <li>Documentation: https://Ayeshmadu.github.io/qm40_dataset_for_ml</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>TODO</li> </ul>"},{"location":"Lmod_run/","title":"Lmod_run module","text":""},{"location":"Lmod_run/#qm40_dataset_for_ml.Lmod_run.RunLmodCalc","title":"<code> RunLmodCalc        </code>","text":"<ol> <li>Class to Run Local vibrational mode calculations.</li> <li>Generate a csv file from extracted QM information. (any name can be given)</li> <li>Generate the geometry and LModA csv files for each molecules</li> </ol> <p>current_dir_path (str): path to the folder which has optimized compounds as separate folders dataset (str): csv file with the information of smile and Zinc_id (optional)</p> Source code in <code>qm40_dataset_for_ml/Lmod_run.py</code> <pre><code>class RunLmodCalc:\n    \"\"\"\n    1. Class to Run Local vibrational mode calculations.\n    2. Generate a csv file from extracted QM information. (any name can be given)\n    3. Generate the geometry and LModA csv files for each molecules\n\n    Args:\n    current_dir_path (str): path to the folder which has optimized compounds as separate folders\n    dataset (str): csv file with the information of smile and Zinc_id (optional)\n\n    \"\"\"\n\n    def __init__(self, current_dir_path, dataset=None):\n        self.current_dir_path = current_dir_path\n        current_path = os.getcwd()\n        target_folder_path = os.path.join(current_path, \"Lmod_geom_results\")\n        if not os.path.exists(target_folder_path):\n            os.makedirs(target_folder_path)\n        self.target_folder_path = target_folder_path\n        self.dataset = dataset\n        self.dataset_name = \"QM_parameters.csv\"\n\n    # running g16 results and Lmod calculations to extract g16 info, coordinates and Lmod info\n    def run_lmod_collect_g16_info(self) -&gt; list:\n        list_dir = [\n            name\n            for name in os.listdir(self.current_dir_path)\n            if os.path.isdir(os.path.join(self.current_dir_path, name))\n        ]\n        qm_parameter_collector = []\n        smiles = []\n        img_freq = []\n        for current_folder in list_dir:\n            current_folder_path = os.path.join(self.current_dir_path, current_folder)\n\n            if ut.incomplete_running_checker(current_folder_path, current_folder):\n                if ut.imaginary_freq_checker(current_dir_path, current_dir):\n\n                    if self.dataset is not None:\n                        smile = ut.get_smile(self.dataset, current_folder)\n                        smiles.append(smile)\n                    ut.lmod_clac(\n                        current_folder_path, current_folder, self.target_folder_path\n                    )\n                    g16 = gaussian_info_extractor.GaussianInfoExtractor(\n                        current_folder_path, current_folder\n                    )\n                    imaginary_freq = g16.imaginary_freq_checker()\n\n                    if imaginary_freq is not None:\n                        img_freq.append(imaginary_freq)\n\n                    parameters, coordinates = g16.making_csvs()\n                    qm_parameter_collector.append(parameters)\n                    coordinate_name = f\"{current_folder_path}_xyz.csv\"\n                    coordinates.to_csv(coordinate_name)\n                    os.chdir(self.target_folder_path)\n                    source_path = os.path.join(current_folder_path, coordinate_name)\n                    target_fol_path = os.path.join(\n                        self.target_folder_path, current_folder\n                    )\n                    shutil.copy2(source_path, target_fol_path)\n        return qm_parameter_collector, smiles, img_freq\n\n    # generate main dataset\n    def final_dataset_generator(self) -&gt; None:\n        qm_parameters, smiles, img_freq = self.run_lmod_collect_g16_info()\n        print(smiles)\n        column_names = [\n            \"Internal_E(0K)\",\n            \"HOMO\",\n            \"LUMO\",\n            \"Polarizability\",\n            \"spatial extent\",\n            \"dipol_mom\",\n            \"ZPE\",\n            \"rot1\",\n            \"rot2\",\n            \"rot3\",\n            \"Inter_E(298)\",\n            \"Enthalpy\",\n            \"Free_E\",\n            \"CV\",\n            \"Entropy\",\n        ]\n        df_init = pd.DataFrame(qm_parameters, columns=column_names)\n\n        if self.dataset is not None:\n            smile_df = pd.DataFrame(smiles)\n            df_init = pd.concat([smile_df[0], df_init], axis=1)\n            df_init = df_init.rename(columns={0: \"smile\"})\n            df_init.to_csv(self.dataset_name, index=False)\n            print(f\"Final dataset saved as: {self.dataset_name}\")\n\n        else:\n            df_init.to_csv(\"QM_parameters.csv\", index=False)\n            print(f\"Final dataset saved as: {self.dataset_name}\")\n\n        if len(img_freq) != 0:\n            df_img_freq = pd.DataFrame(img_freq, columns=\"imaginary_freq\")\n            df_img_freq.to_csv(\"imaginary_frequency_detect.csv\")\n</code></pre>"},{"location":"QM40data_search/","title":"QM40data_search module","text":""},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/Ayeshmadu/QM40_dataset_for_ML/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>QM40_Dataset could always use more documentation, whether as part of the official QM40_Dataset docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/Ayeshmadu/QM40_dataset_for_ML/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up QM40_dataset_for_ML for local development.</p> <ol> <li> <p>Fork the QM40_dataset_for_ML repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/QM40_dataset_for_ML.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv QM40_dataset_for_ML\n$ cd QM40_dataset_for_ML/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 QM40_dataset_for_ML tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/Ayeshmadu/QM40_dataset_for_ML/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"gaussian_info_extractor/","title":"gaussian_info_extractor module","text":""},{"location":"gaussian_info_extractor/#qm40_dataset_for_ml.gaussian_info_extractor.GaussianInfoExtractor","title":"<code> GaussianInfoExtractor        </code>","text":"<p>Class to Extract Qm parameters from Gaussian16 input file</p> <p>current_dir_path (str): path for optimized compounds(each are inside a folder named Zinc_id) current_dir (str): Specific molecule's Zinc_id (folder names)</p> Source code in <code>qm40_dataset_for_ml/gaussian_info_extractor.py</code> <pre><code>class GaussianInfoExtractor:\n    \"\"\"\n    Class to Extract Qm parameters from Gaussian16 input file\n\n    Args:\n    current_dir_path (str): path for optimized compounds(each are inside a folder named Zinc_id)\n    current_dir (str): Specific molecule's Zinc_id (folder names)\n\n    \"\"\"\n\n    def __init__(self, current_dir_path, current_dir):\n        self.current_dir_path = current_dir_path\n        self.current_dir = current_dir\n        self.output_data = None\n\n    # read output files\n    def output_file_reader(self) -&gt; str:\n        os.chdir(self.current_dir_path)\n        gout_name = f\"{self.current_dir}_run.out\"\n        gout_path = os.path.join(self.current_dir_path, gout_name)\n        try:\n            with open(gout_path, \"r\") as f:\n                lines = f.readlines()\n            self.output_data = (lines, gout_name)\n        except FileNotFoundError:\n            print(\n                f\"Gaussian out file {gout_name} not found in {self.current_dir_path}, skipping g_out data.\"\n            )\n\n        return self.output_data\n\n    # find frequencies and report imaginary frequencies\n    def imaginary_freq_checker(self) -&gt; list:\n        lines, out_file = self.output_file_reader()\n        target_word = \"Frequencies\"\n        for line in lines:\n            row = line.strip()\n\n            if target_word in row:\n                freq_line = row\n                values_str = freq_line.split()\n                values_str = values_str[2:]\n                values = [float(value.strip()) for value in values_str]\n                for value in values:\n\n                    if value &lt; 0:\n                        return self.current_dir\n\n    def intial_coord_extract(self) -&gt; list:\n        ini_xyz = []\n        xyz_file = f\"{self.current_dir}.xyz\"\n        with open(xyz_file, \"r\") as file:\n            first_line = file.readline().rstrip()\n        length = int(first_line)\n        ini_coord = []\n        ini_coordinates = \"Symbolic Z-matrix:\"\n        lines, gauss_out = self.output_file_reader()\n\n        for i, line in enumerate(lines):\n            row = line.strip()\n\n            if ini_coordinates in row:\n\n                for index in range(length):\n\n                    initial_xyz = lines[index + 2 + i].strip().split()\n                    ini_xyz.append(initial_xyz)\n        return ini_xyz, length\n\n    # Extract QM parameters ffrom gaussian output file using keywords\n    def qm_info_collector(self) -&gt; list:\n        opt = []\n        charges = []\n        lines, gauss_out = self.output_file_reader()\n        print(self.current_dir)\n        start_reading = False\n        start_line = (\n            \"#P Geom=AllCheck Guess=TCheck SCRF=Check GenChk RB3LYP/6-31G(2df,p) Fr\"\n        )\n        opt_coordinates = \"Standard orientation:\"\n        elec_E = \"SCF Done\"\n        isotropic = \"Isotropic polarizability\"\n        HOMO = \"Alpha  occ. eigenvalues\"\n        Muliliken_charges = \"Mulliken charges:\"\n        electro = \"Electronic spatial extent (au):\"\n        vibrational = \"Zero-point vibrational energy\"\n        dipol = \"Dipole moment (field-independent basis, Debye):\"\n        Internal_energy = \"Sum of electronic and thermal Energies=\"\n        start_reading = False\n        initial_coordinates, length = self.intial_coord_extract()\n        for i, line in enumerate(lines):\n            row = line.strip()\n\n            if start_line in row:\n                start_reading = True\n\n            if not start_reading:\n                continue\n\n            if opt_coordinates in row:\n                for num1 in range(length):\n                    num1 = num1 + 5\n                    num1 = i + num1\n                    xyz = lines[num1].strip()\n                    xyz_coord = xyz.split()[3:6]\n                    opt.append(xyz_coord)\n\n            elif elec_E in row:\n                tot_ele_E_0K = row.split()[4]\n\n            elif HOMO in row:\n                last_HOMO_line = row.split()[-1]\n                first_LUMO_line = lines[i + 1].strip().split()[4]\n\n            elif isotropic in row:\n                polarizability = row.split()[5]\n\n            elif Muliliken_charges in row:\n                for num in range(length):\n                    num = num + 2\n                    num = i + num\n                    Mili = lines[num].strip().split()[2]\n                    charges.append(Mili)\n\n            elif dipol in row:\n                electronic = lines[i - 2].strip().split()[5]\n                dipol_moment = lines[i + 1].strip().split()[7]\n\n            elif vibrational in row:\n                zero_point = lines[i + 1].strip().split()[0]\n                rotational = lines[i - 2].strip().split()\n                rotational1 = rotational[3]\n                rotational2 = rotational[4]\n                rotational3 = rotational[5]\n\n            elif Internal_energy in row:\n                Internal_energy_295K = row.split()[6]\n                Enthalpy = lines[i + 1].strip().split()[6]\n                Free_E = lines[i + 2].strip().split()[7]\n                cv_entropy = lines[i + 6].strip()\n                cv = cv_entropy.split()[2]\n                entropy = cv_entropy.split()[3]\n\n        return [\n            initial_coordinates,\n            opt,\n            charges,\n            tot_ele_E_0K,\n            last_HOMO_line,\n            first_LUMO_line,\n            polarizability,\n            electronic,\n            dipol_moment,\n            zero_point,\n            rotational1,\n            rotational2,\n            rotational3,\n            Internal_energy_295K,\n            Enthalpy,\n            Free_E,\n            cv,\n            entropy,\n        ]\n\n    # making CSVs\n    def making_csvs(self) -&gt; list:\n        n = self.qm_info_collector()\n        qm_parameters = n[3:18]\n        init_coordinates = n[0]\n        init_name = [\"atomic num\", \"ini_x\", \"init_y\", \"init_z\"]\n        df_init = pd.DataFrame(init_coordinates, columns=init_name)\n        final_name = [\"final_x\", \"final_y\", \"final_z\"]\n        df_final = pd.DataFrame(n[1], columns=final_name)\n        charge_name = [\"Charge\"]\n        df_charges = pd.DataFrame(n[2], columns=charge_name)\n        df_coordinates = pd.concat([df_init, df_final, df_charges], axis=1)\n        return qm_parameters, df_coordinates\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install QM40_Dataset, run this command in your terminal:</p> <pre><code>pip install QM40_dataset_for_ML\n</code></pre> <p>This is the preferred method to install QM40_Dataset, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install QM40_Dataset from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/Ayeshmadu/QM40_dataset_for_ML\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use QM40_Dataset in a project:</p> <pre><code>import qm40_dataset_for_ml\n</code></pre>"},{"location":"utils/","title":"utils module","text":""}]}